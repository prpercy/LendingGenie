{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermark import watermark\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.options.display.float_format = '{:0,.2f}'.format #avoid scientific notation, and thousands separator \n",
    "import numpy as np\n",
    "\n",
    "import hvplot.pandas\n",
    "import seaborn as sns\n",
    "hvplot.extension('bokeh')\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data cleanup and high-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System Requirements\n",
    "\n",
    "print(watermark())\n",
    "print(watermark(iversions=True, globals_=globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the Kaggle database file into a Pandas DataFrame\n",
    "df = pd.read_csv(\n",
    "    Path(\"../../LG_Resources/Resources/lending-club/accepted_2007_to_2018Q4.csv/accepted_2007_to_2018Q4.csv\"),  \n",
    "    infer_datetime_format=True,\n",
    "    parse_dates = True,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of NAN values in each column\n",
    "\n",
    "nan_values = pd.DataFrame(df.isna().sum(),columns = [\"NAN Count\"]).reset_index()\n",
    "# nan_values.sort_values(nan_values.columns[1], ascending=False) #commented out for memory use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check average number of NAN values and how many columns have NAN values over 500k\n",
    "display(nan_values[(nan_values['NAN Count'] > 500000)].shape)\n",
    "nan_values['NAN Count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with over 500k NAN values + ID column (not relevant) and create new dataframe\n",
    "\n",
    "drop_columns = nan_values[(nan_values['NAN Count'] > 500000)]['index'].tolist() \n",
    "drop_columns.extend(['id','url','title','zip_code']) #deemed unnecessary after review \n",
    "df = df.drop(drop_columns, axis=1)\n",
    "df.isna().sum().mean()\n",
    "# drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns in alphabetical order and print list of columns for further data analysis\n",
    "ordercolumns = df.columns.tolist()\n",
    "ordercolumns.sort()\n",
    "df = df[ordercolumns]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adjust df to load into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all loan status values\n",
    "status = df['loan_status'].dropna().unique().tolist()\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with values considered default (i.e. Y value)\n",
    "defaultstatus = status[2:-2]\n",
    "defaultstatus.append(status[-1])\n",
    "defaultstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items not considered default \n",
    "goodstatus = [i for i in status if i not in defaultstatus]\n",
    "goodstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Default'] = np.where(df['loan_status'].isin(defaultstatus), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all Y value loans have been tagged correctly\n",
    "print(df[df['Default']==1]['loan_status'].isin(defaultstatus).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check eveyrthing was tagged correctly\n",
    "check = pd.DataFrame(df['loan_status'].value_counts())\n",
    "check['defaults'] = df[df['Default'] == 1]['loan_status'].value_counts()\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['loan_status'],axis=1,inplace=True)\n",
    "# df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'])\n",
    "# df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "# df['last_credit_pull_d'] = pd.to_datetime(df['last_credit_pull_d'])\n",
    "# df['last_pymnt_d'] = pd.to_datetime(df['last_pymnt_d'])\n",
    "# df.drop(['emp_title'],axis=1,inplace=True)\n",
    "df.drop(columns= ['emp_title','earliest_cr_line','issue_d','last_credit_pull_d','last_pymnt_d','Default','loan_status'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changetypes = pd.DataFrame(df.dtypes,columns = ['type']).reset_index()\n",
    "changetypes = changetypes[changetypes['type']=='object']\n",
    "changetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict = {}\n",
    "for colname in changetypes[\"index\"]:\n",
    "    counter = 0.0\n",
    "    col_dict = {}\n",
    "    for elem in df[colname].unique():\n",
    "        col_dict[elem] = counter\n",
    "        counter = counter+1\n",
    "    newdict[colname] = col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slight manual adjustments to dictionary above to remove nan values \n",
    "cleaner = {'addr_state': {'PA': 0.0,  'SD': 1.0,  'IL': 2.0,  'NJ': 3.0,\n",
    "  'GA': 4.0,  'MN': 5.0,  'SC': 6.0,  'RI': 7.0,  'TX': 8.0,  'NC': 9.0,  'CA': 10.0,  'VA': 11.0,\n",
    "  'AZ': 12.0,  'NY': 13.0,  'IN': 14.0,  'MD': 15.0,  'KS': 16.0,  'NM': 17.0,  'AL': 18.0,  'WA': 19.0,\n",
    "  'MO': 20.0,  'OH': 21.0,  'LA': 22.0,  'FL': 23.0,  'CO': 24.0,  'MI': 25.0,  'TN': 26.0,\n",
    "  'DC': 27.0,  'MA': 28.0,  'WI': 29.0,  'HI': 30.0,  'VT': 31.0,  'DE': 32.0,  'NH': 33.0,  'NE': 34.0,\n",
    "  'CT': 35.0,  'OR': 36.0,  'AR': 37.0,  'MT': 38.0,  'NV': 39.0,  'WV': 40.0,  'WY': 41.0,  'OK': 42.0,\n",
    "  'KY': 43.0,  'MS': 44.0,  'ME': 45.0,  'UT': 46.0,  'ND': 47.0,  'AK': 48.0,  'ID': 50.0,  'IA': 51.0},\n",
    " 'application_type': {'Individual': 0.0, 'Joint App': 1.0},\n",
    " 'debt_settlement_flag': {'N': 0.0, 'Y': 1.0},\n",
    " 'disbursement_method': {'Cash': 1.0, 'DirectPay': 2.0},\n",
    " 'emp_length': {'10+ years': 10.0,  '3 years': 3.0,  '4 years': 4.0,\n",
    "  '6 years': 6.0,  '1 year': 1.0,  '7 years': 7.0,  '8 years': 8.0,\n",
    "  '5 years': 5.0,  '2 years': 2.0,  '9 years': 9.0,  '< 1 year': 1.0},\n",
    " 'grade': {'C': 0.0,  'B': 1.0,  'F': 2.0,  'A': 3.0,  'E': 4.0,  'D': 5.0,  'G': 6.0},\n",
    " 'hardship_flag': {'N': 0.0, 'Y': 1.0},\n",
    " 'home_ownership': {'MORTGAGE': 0.0,  'RENT': 1.0,\n",
    "      'OWN': 2.0,  'ANY': 3.0,'NONE': 4.0,  'OTHER': 5.0},\n",
    " 'initial_list_status': {'w': 0.0, 'f': 1.0},\n",
    " 'purpose': {'debt_consolidation': 0.0,  'small_business': 1.0,\n",
    "      'home_improvement': 2.0,  'major_purchase': 3.0,\n",
    "      'credit_card': 4.0,  'other': 5.0,\n",
    "      'house': 6.0,  'vacation': 7.0,\n",
    "      'car': 8.0,  'medical': 9.0,\n",
    "      'moving': 10.0,  'renewable_energy': 11.0,\n",
    "      'wedding': 12.0,  'educational': 13.0,},\n",
    " 'pymnt_plan': {'n': 0.0, 'y': 1.0},\n",
    " 'sub_grade': {'C4': 0.0,  'C1': 1.0,\n",
    "      'B4': 2.0,  'C5': 3.0,\n",
    "      'F1': 4.0,  'C3': 5.0,\n",
    "      'B2': 6.0,  'B1': 7.0,\n",
    "      'A2': 8.0,  'B5': 9.0,\n",
    "      'C2': 10.0,  'E2': 11.0,\n",
    "      'A4': 12.0,  'E3': 13.0,\n",
    "      'A1': 14.0,  'D4': 15.0,\n",
    "      'F3': 16.0,  'D1': 17.0,\n",
    "      'B3': 18.0,  'E4': 19.0,\n",
    "      'D3': 20.0,  'D2': 21.0,\n",
    "      'D5': 22.0,  'A5': 23.0,\n",
    "      'F2': 24.0,  'E1': 25.0,\n",
    "      'F5': 26.0,  'E5': 27.0,\n",
    "      'A3': 28.0,  'G2': 29.0,\n",
    "      'G1': 30.0,  'G3': 31.0,\n",
    "      'G4': 32.0,  'F4': 33.0,\n",
    "      'G5': 34.0},\n",
    " 'term': {' 36 months': 0.0, ' 60 months': 1.0},\n",
    " 'verification_status': {'Not Verified': 0.0,\n",
    "  'Source Verified': 1.0,\n",
    "  'Verified': 2.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldf = df.replace(cleaner)\n",
    "modeldf = modeldf.fillna(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K Means (unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k4 = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k4.fit(modeldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_segments_k4 = model_k4.predict(modeldf)\n",
    "print(loan_segments_k4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k6 = KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k6.fit(modeldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_segments_k6 = model_k6.predict(modeldf)\n",
    "print(loan_segments_k6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel_predictions = modeldf.copy()\n",
    "kmodel_predictions['Segments k=4'] = loan_segments_k4\n",
    "kmodel_predictions['Segments k=6'] = loan_segments_k6\n",
    "kmodel_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k4plot = kmodel_predictions.hvplot.scatter(\n",
    "    x=\"annual_inc\", \n",
    "    y=\"fico_range_high\", \n",
    "    by=\"Segments k=4\",\n",
    "    title = \"Scatter Plot by Segment - k=4\"\n",
    ")\n",
    "\n",
    "k6plot = kmodel_predictions.hvplot.scatter(\n",
    "    x=\"annual_inc\", \n",
    "    y=\"fico_range_high\", \n",
    "    by=\"Segments k=6\",\n",
    "    title = \"Scatter Plot by Segment - k=6\"\n",
    ")\n",
    "\n",
    "\n",
    "k4plot + k6plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate categorical (ones we assigned numebers to) from non-categorical columns\n",
    "categorical = [i for i in changetypes['index']]\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncategorical = [i for i in modeldf.columns if i not in categorical]\n",
    "noncategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaled_data = StandardScaler().fit_transform(modeldf[noncategorical])\n",
    "scaled_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new scaled df\n",
    "modeldf_scaled = pd.DataFrame(scaled_data)\n",
    "modeldf_scaled.columns = noncategorical\n",
    "modeldf_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add back ncategorical data\n",
    "modeldf_scaled[categorical] = modeldf[categorical]\n",
    "modeldf_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnames = noncategorical\n",
    "# columnames.extend(categorical)\n",
    "# columnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeldf_scaled.columns = columnames\n",
    "modeldf_scaled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K Means (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k4 = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k4.fit(modeldf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_segments_k4 = model_k4.predict(modeldf_scaled)\n",
    "print(loan_segments_k4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k6 = KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k6.fit(modeldf_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_segments_k6 = model_k6.predict(modeldf_scaled)\n",
    "print(loan_segments_k4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_kmodel_predictions = modeldf_scaled.copy()\n",
    "sc_kmodel_predictions['Segments k=4'] = loan_segments_k4\n",
    "sc_kmodel_predictions['Segments k=6'] = loan_segments_k6\n",
    "sc_kmodel_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_k4plot = sc_kmodel_predictions.hvplot.scatter(\n",
    "    x=\"int_rate\", \n",
    "    y=\"fico_range_high\", \n",
    "    by=\"Segments k=4\",\n",
    "    title = \"Scatter Plot by Segment - k=4\"\n",
    ")\n",
    "\n",
    "sc_k6plot = sc_kmodel_predictions.hvplot.scatter(\n",
    "    x=\"int_rate\", \n",
    "    y=\"fico_range_high\", \n",
    "    by=\"Segments k=6\",\n",
    "    title = \"Scatter Plot by Segment - k=6\"\n",
    ")\n",
    "\n",
    "\n",
    "sc_k4plot + sc_k6plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "254cf7c41a7d979248105ee34cd0895207f9ccbd9d32ab3263db7a90bb897922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
